---
documentclass: article
title: "Solvabilté II : Calibration des chocs de capital de solvabilité requis avec expected shortfall."
author: "Kevin BAMOUNI"
date: "01/09/2020"
geometry: margin=1in
fontfamily: mathptmx
fontsize: 11pt
lang: fr-FR
# spacing: double
endnote: no
citecolor: cyan
output:
  pdf_document:
    df_print: kable
    fig_width: 7
    fig_height: 4
    fig_caption: true
    citation_package: natbib
    latex_engine: xelatex
    number_sections: true
bibliography: master.bib
---
  
  
    
Conservatoire National des Arts et Métiers (CNAM Paris) / EFAB  
Master 2 Actuariat  
STA217 Gestion quantitative du risque en finance et assurance  
  
Projet de fin d'année basé sur l'article "Solvency II solvency capital requirement for life insurance companies based on expected shortfall" de Tim J. Boonen publié en Octobre 2017.


```{r, echo = FALSE, fig.align = 'center', message=FALSE}
# Libraries
library(quantmod)
library(ggplot2)
library(dplyr)
library(cowplot)
library(lifecontingencies)
library(reshape2)
library(readr)
library(RcppRoll)
library(cvar)
library(tibble)
library(lubridate)
# fichier de functions
source("es_calibration_functions.R")
source("data_management.R")
```


```{r, echo = FALSE, fig.align = 'center', message=FALSE}
# MSCI data load: source : https://www.msci.com/developed-markets / Data d'extraction des données: 20 aout 2020
msci <- read.csv(file = 'data/historyindex.csv', sep = ";", header = TRUE)[ ,c('Date', 'Price')]
msci$Date <- as.Date(msci$Date, "%d-%m-%Y")

# Utilisation des séries temporelle à la place : 
msci_ts <- ts(msci$Price, start = c(1969,12,31), frequency = 12)

# Importdes données de taux : courbe historique de la bce / taux spot sans risque obligation noté AAA / extration 27/08/2020
bce_spot_rate_curve_histo <- read.csv(file = 'data/courbe_des_taux_historique_bce.csv', sep = ";", header = TRUE)
names(bce_spot_rate_curve_histo) <- gsub("YC.B.U2.EUR.4F.G_N_A.SV_C_YM.SR_", "", names(bce_spot_rate_curve_histo))

# importation des données de taux : courbe historique de la banque d'angleterre / taux spot sans risque 
#glc_spot_rate_curve_histo <- read.csv(file = 'data/courbe_des_taux_historique_bce.csv', sep = ";", header = TRUE)

```


# INTRODUCTION

Academic workflow, certainly in political science, is at a crossroads. The *American Journal of Political Science* (*AJPS*) announced a (my words) ["show your work" initiative](http://ajps.org/2015/03/26/the-ajps-replication-policy-innovations-and-revisions/) in which authors who are tentatively accepted for publication at the journal must hand over the raw code and data that produced the results shown in the manuscript. The editorial team at *AJPS* then reproduces the code from the manuscript. Pending successful replication, the manuscript moves toward publication. The *AJPS* might be at the fore of this movement, and it could be the most aggressive among political science journals, but other journals in our field have signed the joint [Data Access & Research Transparency](http://www.dartstatement.org/) (DART) initiative. This, at a bare minimum, requires uploading code from quantitatively-oriented published articles to in-house directories hosted by the journal or to services like [Dataverse](http://dataverse.org/).

# SOLVABILITE 2


# MODELE DE L'ARTICLE : ESPECTED SHORTFALL POUR LA CALIBRATION DES CHOCS DE CALCUL DU SCR (CSR)


## DESCRIPTION


## MODELE DE CALIBRATION DES CHOCS DE CAPITAL DE SOLVABILITE REQUIS

### CALIBRATION DU CHOC SUR LES ACTIONS

Calibration du choc scr sur les actions

```{r, echo = FALSE, fig.align = 'center', message=FALSE, fig.cap= "Rendement de l'indice MSCI"}
# Most basic bubble plot
p1 <- ggplot(msci, aes(x=Date, y=Price)) +
  geom_area(fill = "lightgray", color="blue") + 
  xlab("Date") + ylab("Price")  + ggtitle("Evolution de la valeur de l'indice MSCI") + theme_classic()

# formule de calcul : (Pt - P(t-1))/P(t-1)
msci_return <-data.frame(diff(msci_ts)/stats::lag(msci_ts, -1))
colnames(msci_return) <- c("msci_return")

# anualisation
#msci_return$msci_return <- 1+msci_return$msci_return
msci_return_annualized <-data.frame(roll_prod(1+msci_return$msci_return, n =12) - 1)
colnames(msci_return_annualized) <- c("msci_return_annualized")

p2 <- ggplot(msci_return_annualized, aes(x=index(msci_return_annualized), y=msci_return_annualized)) +
  geom_line( color="red") + 
  xlab("index") + ylab("return") + theme_classic()

plot_grid(p1, p2, ncol = 1, align = "v")
```

Distribution des rendements

```{r, echo = FALSE, fig.align = 'center', message=FALSE, fig.cap= "Rendement de l'indice MSCI"}
p3 <- ggplot(msci_return_annualized, aes(msci_return_annualized)) +
  geom_histogram( bins = 50, color="darkgreen", fill="white") +
  xlab("return") + ylab("Nombre d'occurrence") + ggtitle("Rendement de l'indice MSCI") +
  theme_classic()

p4 <- ggplot(msci_return_annualized, aes(msci_return_annualized)) +
  geom_density(color="goldenrod2", fill = "gold1", alpha = 0.1) +
  stat_function(fun = dnorm, args = list(mean(msci_return_annualized$msci_return_annualized), sd(msci_return_annualized$msci_return_annualized)), color = "red") +
  geom_vline(xintercept = mean(msci_return_annualized$msci_return_annualized), colour = "#FF3721", linetype = "dashed") +
  xlab("return") + ylab("frequence en %") + 
  theme_classic()

plot_grid(p3, p4)
```

Value at risque historique sur les données de rendements annualisées 

```{r, echo = FALSE, fig.align = 'center', message=FALSE}
# Calcul de la VAR historique des données
histo_VAR <- round(quantile(msci_return_annualized, probs = c(0.005), na.rm = TRUE, type = 1), 4)
```

Value at risque d'une loi normale théorique

```{r, echo = FALSE, fig.align = 'center', message=FALSE}
# msci_return$msci_return[msci_return$msci_return<histo_VAR[3]]
histo_ES <- round(mean(msci_return_annualized$msci_return_annualized[msci_return_annualized$msci_return_annualized<=round(quantile(msci_return_annualized, probs = c(0.0115), na.rm = TRUE, type = 1), 4)]), 4)
```

: Calibration des chocs "global equity" avec la VaR et l'ES incluant un ajustement symétrique de 7,5%.

$\alpha(\%)$ |$\theta(\alpha)(\%)$ | $VaR_{\alpha}(\%)$    |$ES_{\theta(\alpha)}(\%)$|
-------------|-------------        | -------------         |---------------------    |
99.5         | 98.85               | `r histo_VAR*100-7.5` | `r histo_ES*100-7.5`    |



### CALIBRATION DU CHOC SUR LES TAUX

```{r, echo = FALSE, fig.align = 'center', message=FALSE}
#bce_spot_rate_curve_histo_tible <- as_tibble(bce_spot_rate_curve_histo)
#bce_spot_rate_curve_histo_tible <- bce_spot_rate_curve_histo_tible %>% mutate(DATE = as_date(DATE, format="%d/%m/%y"))
#filter(bce_spot_rate_curve_histo_tible, DATE == as_date("2/08/2020", format="%d/%m/%y"))
melt_bce_spot_rate_curve_histo <- melt(bce_spot_rate_curve_histo[1:5,])

#melt_bce_spot_rate_curve_histo$DATE <- as.Date(melt_bce_spot_rate_curve_histo$DATE,format="%d/%m/%y")
#melt_bce_spot_rate_curve_histo <- filter(bce_spot_rate_curve_histo, DATE >= as.Date('01/01/2020', format="%d/%m/%y"))

p8 <- ggplot(melt_bce_spot_rate_curve_histo, aes(variable, value, group=DATE, color=DATE)) + geom_line(show.legend = TRUE)
p8
```



```{r, echo = FALSE, fig.align = 'center', message=FALSE}

```



### CALIBRATION DU CHOC SUR LA LONGEVITE

```{r, echo = FALSE, fig.align = 'center', message=FALSE, fig.cap= "Evolution de la Table de mortalité en France entre 1992 et 2009"}
p5 <- ggplot(FR, aes(Age, qx, group=Year, color=Year)) + geom_line(aes(color = factor(Year))) +
  geom_vline(xintercept = "105-109", colour = "black", linetype = "dashed") +
   geom_vline(xintercept = "55-59", colour = "black", linetype = "dashed")+
    ylab("Probabilité de décès") +  scale_x_discrete(limits=c("0","1-4","5-9","10-14","15-19","20-24","25-29","30-34","35-39","40-44","45-49","50-54","55-59","60-64","65-69","70-74","75-79","80-84","85-89","90-94","95-99","100-104","105-109","110+"),guide = guide_axis(n.dodge = 2)) +
  theme_classic()

p5

# TODO : Fix le 5 qui est en plein milieu sans raison valable là    
```


Calcul des ES En moyenne pour toutes les tranches d'age et tous les pays.

```{r, echo = FALSE, fig.align = 'center', message=FALSE}
join_qx_df <- left_join(DEN_reshape, FR_reshape, by='Age') %>% left_join(EST_reshape, by = 'Age') %>% left_join(HUN_reshape, by = 'Age') %>% left_join(IT_reshape, by = 'Age') %>% left_join(POL_reshape, by = 'Age') %>% left_join(SWE_reshape, by = 'Age') %>% left_join(ENGW_reshape, by = 'Age') %>% left_join(CZE_reshape, by = 'Age')

join_qx_df <- column_to_rownames(join_qx_df, var = "Age")

es_theo <- function(vect, qq){
  return(ES(qnorm, x = qq, mean = mean(vect), sd = sd(vect)))
}

var_theo <- function(vect, qq){
  return(VaR(qnorm, x = qq, mean = mean(vect), sd = sd(vect)))
}

# Theta choisi tel la var = es
es_longe <- round(mean(-apply(join_qx_df[1:22,], 1, es_theo, qq=0.0129))*100,2)

var_longe <- round(mean(-apply(join_qx_df[1:22,], 1, var_theo, qq=0.005))*100,2)
```



```{r, echo = FALSE, fig.align = 'center', message=FALSE, fig.cap= "Another amazing plot"}
dt1 <- melt(join_qx_df["55-59",])


p6 <- ggplot(dt1, aes(value)) +
    geom_density(color="aquamarine2", fill = "aquamarine2", alpha = 0.1) +
    stat_function(fun = dnorm, args = list(mean(dt1$value), sd(dt1$value)), color = "brown") +
    geom_vline(xintercept = mean(dt1$value), colour = "#FF3721", linetype = "dashed") +
    xlab("taux d'évolution") + ylab("frequence en %") + 
    theme_classic()
  

p7 <- ggplot(dt1, aes(sample=value)) + stat_qq(color="darkgrey") + stat_qq_line(color = "brown")+ 
    theme_classic()

plot_grid(p6, p7, ncol = 1, align = "v")

```


: Calibration des chocs "longévité" avec la VaR et l'ES.

$\alpha(\%)$   | $\theta(\alpha)(\%)$ | $VaR_{\alpha}(\%)$    |$ES_{\theta(\alpha)}(\%)$|
---------------|-------------         | -------------         |---------------------    |
99.5           | 98.71                | `r var_longe`         | `r es_longe`            |

# THEORIE DES VALEURS EXTREMES POUR LA CALIBRATION DES CHOCS

# CONCLUSION

# REFERENCES

# ANNEXES  avec codes, figures en plus etc.).

## Packages R

## Articles
